{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kaneelgit/ConnectFourZero/blob/main/Deep_QL_Connect4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CS7lUh94VOzv",
    "outputId": "9c7d3ed1-5882-4df9-d0c0-b665a1189601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ConnectFourZero'...\n",
      "remote: Enumerating objects: 13, done.\u001b[K\n",
      "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 13 (delta 1), reused 10 (delta 1), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (13/13), done.\n",
      "Resolving deltas: 100% (1/1), done.\n"
     ]
    }
   ],
   "source": [
    "#clone the repo\n",
    "!git clone https://github.com/kaneelgit/ConnectFourZero.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TVVaERkwV2i_"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "from ConnectFour.game import ConnectFour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Neural Network Model\n",
    "\n",
    "#create a convolution block\n",
    "class ConvBlock(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = \"same\"):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=out_channels, kernel_size=kernel_size, strides=stride, padding=padding)\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvBlock(in_channels, out_channels)\n",
    "        self.conv2 = ConvBlock(in_channels, out_channels)\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = tf.keras.layers.Conv2D(filters=out_channels, kernel_size=1, strides=1, padding=\"same\")\n",
    "        else:\n",
    "            self.shortcut = lambda x: x\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        residual = self.shortcut(inputs)\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = x + residual\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = tf.keras.Sequential([\n",
    "    ConvBlock(3, 64, kernel_size = 3),\n",
    "    ResidualBlock(64, 64),\n",
    "    ResidualBlock(64, 64),\n",
    "    ResidualBlock(64, 64),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation = 'linear')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = Adam())\n",
    "model.build(input_shape = (None, 5, 6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_state_int(board):\n",
    "    \n",
    "    board_state = np.zeros([5, 6, 3])\n",
    "    \n",
    "    for r, row in enumerate(board):\n",
    "        for c, col in enumerate(row):\n",
    "            if col == 'X':\n",
    "                board_state[r, c, 0] = 1\n",
    "            if col == 'O':\n",
    "                board_state[r, c, 1] = 2\n",
    "                  \n",
    "    \n",
    "    return board_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "gamma = 0.95\n",
    "epsilon = 0.09\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "memory = deque(maxlen = 2000)\n",
    "batch_size = 16\n",
    "episodes = 1 #1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   |   |   |   | X |   |\n",
      "|   | O |   |   | O | X |\n",
      "|   | X |   |   | X | O |\n",
      "|   | O |   |   | X | X |\n",
      "| X | X | O | O | O | O |\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "for episode in range(episodes):\n",
    "\n",
    "    #start new game\n",
    "    c4 = ConnectFour()\n",
    "    \n",
    "    #select current player\n",
    "    rand_choice = np.random.randint(1, 3, size = 1) #if 1 computer plays first if 2 computer plays second\n",
    "    if rand_choice == 1:\n",
    "        computer = 'X'\n",
    "    else:\n",
    "        computer = 'O'\n",
    "    \n",
    "    #current state\n",
    "    state = board_state_int(c4.board)\n",
    "    \n",
    "    #append first state\n",
    "    current_game_states = []\n",
    "    current_game_states.append(state)\n",
    "    \n",
    "    #bool to start game and break loop\n",
    "    play_game = True\n",
    "    \n",
    "    while play_game:\n",
    "        \n",
    "        if np.random.rand() <= epsilon:\n",
    "            ## random action\n",
    "            move = np.random.randint(0, 6)\n",
    "            \n",
    "        else:\n",
    "            ## predict from the model\n",
    "            q_preds = model.predict(state[np.newaxis, :])\n",
    "            move = np.argmax(q_preds)\n",
    "            \n",
    "        if c4.make_move(move):\n",
    "            state = board_state_int(c4.board)\n",
    "            current_game_states.append(state)\n",
    "            \n",
    "            if c4.check_winner():\n",
    "                winner = c4.winner\n",
    "                c4.print_board()\n",
    "                break\n",
    "            if all(cell != ' ' for row in c4.board for cell in row):\n",
    "                winner = 'draw'\n",
    "                c4.print_board()\n",
    "                break\n",
    "                \n",
    "            c4.current_player = 'O' if c4.current_player == 'X' else 'X'\n",
    "        \n",
    "        if len(memory) > batch_size:\n",
    "\n",
    "            #get a mini batch\n",
    "            mini_batch = random.sample(memory, batch_size)\n",
    "            \n",
    "            inputs = tf.zeros((batch_size, state.shape[0], state.shape[1], state.shape[2]))\n",
    "            outputs = tf.zeros((batch_size, 6)) #6 is the number of columns\n",
    "            \n",
    "            #get stuff from the mini batch and get qu values and stuff\n",
    "            for i, (cs, ns, r) in enumerate(mini_batch):\n",
    "                \n",
    "                \n",
    "                q_value = r + gamma * tf.reduce_max(model.predict(ns[np.newaxis, :]))\n",
    "                \n",
    "                #predicted q values\n",
    "                pred_q_values = model.predict(cs[np.newaxis, :])\n",
    "                \n",
    "                #add the new q value\n",
    "                pred_q_values[0][move] = q_value\n",
    "                \n",
    "                inputs.numpy()[i] = cs\n",
    "                outputs[i] = pred_q_values\n",
    "                \n",
    "            model.fit(cs[np.newaxis, :], predicted_q_values, verbose = 0, epochs = 5)\n",
    "                \n",
    "                \n",
    "    #if winner is 'X' and random choice was 1. you are the winner add the reward and stuff (+ 1 for win -1 for loss 0 for draw)\n",
    "    if winner == computer:\n",
    "        reward = 1\n",
    "    elif winner != computer:\n",
    "        reward = -1\n",
    "    else:\n",
    "        reward = 0\n",
    "        \n",
    "    #load stuff to memory\n",
    "    for i in range(0, len(current_game_states) - 1):\n",
    "        memory.append((current_game_states[i], current_game_states[i + 1], reward))  \n",
    "        \n",
    "    #save model every 10 episodes\n",
    "    \n",
    "#     if i % 10 == 0 and i != 0:\n",
    "#         save_dir = '' #google drive\n",
    "#         model.save_weights(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    if i % 5 == 0 and i != 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06289318,  0.07582194, -0.9101417 ,  0.13107954, -0.0737991 ,\n",
       "         0.06734793]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-de191f53719d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = board_state_int(c4.board)\n",
    "\n",
    "qpreds = model.predict(state[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(qpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOl6qq+MAY5y+LBNH9FruPC",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
